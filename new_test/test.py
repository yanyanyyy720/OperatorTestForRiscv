# simplified_exporter.py
import os
import sys
import json
import argparse
import subprocess
import tempfile
import shutil
from typing import Dict, List, Optional, Tuple
import numpy as np

from network_util import execute_command

# å¯¼å…¥æ‚¨ç°æœ‰çš„æ¨¡å—
try:
    from define import (
        TFLiteOperatorGenerator,
        build_op,
        convert_to_tflite,
        generate_test_inputs
    )
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå®šä¹‰ç®€å•ç‰ˆæœ¬ç”¨äºæµ‹è¯•
    import tensorflow as tf


    class TFLiteOperatorGenerator:
        def __init__(self):
            self.supported_ops = ['ADD', 'SUB', 'MUL', 'DIV', 'CONV_2D', 'TANH', 'RELU']
            self.size_configs = {
                'small': {'shape_range': [(16, 16), (32, 32)]},
                'medium': {'shape_range': [(32, 32), (64, 64)]},
                'large': {'shape_range': [(64, 64), (128, 128)]},
                'xlarge': {'shape_range': [(128, 128), (256, 256)]},
                'xxlarge': {'shape_range': [(256, 256), (512, 512)]}
            }


    def build_op(op_name, size):
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ¨¡å‹ç”¨äºæµ‹è¯•
        if op_name == "ADD":
            input1 = tf.keras.layers.Input(shape=(10,), name='input1')
            input2 = tf.keras.layers.Input(shape=(10,), name='input2')
            output = tf.keras.layers.Add()([input1, input2])
            return tf.keras.Model(inputs=[input1, input2], outputs=output)
        else:
            input_layer = tf.keras.layers.Input(shape=(10,))
            output_layer = tf.keras.layers.Dense(1)(input_layer)
            return tf.keras.Model(inputs=input_layer, outputs=output_layer)


    def convert_to_tflite(model, op_name):
        converter = tf.lite.TFLiteConverter.from_keras_model(model)
        return converter.convert()


    def generate_test_inputs(model, input_types):
        if len(model.inputs) == 2:
            return [np.random.randn(1, 10).astype(np.float32),
                    np.random.randn(1, 10).astype(np.float32)]
        return [np.random.randn(1, 10).astype(np.float32)]

# TVMç›¸å…³å¯¼å…¥
try:
    import tvm
    from tvm import relay
    from tvm.contrib import graph_executor
    import tflite

    TVM_AVAILABLE = True
except ImportError:
    TVM_AVAILABLE = False
    print("è­¦å‘Š: TVMæœªå®‰è£…ï¼ŒTVMå¯¼å‡ºåŠŸèƒ½å°†ä¸å¯ç”¨")

# å¹³å°å®šä¹‰
TARGET_PLATFORMS = {
    "rv": {
        "target": tvm.target.Target(
            "llvm -mtriple=riscv64-linux-gnu -mcpu=generic-rv64 -mabi=lp64d -mattr=+64bit,+m,+a,+f,+d,+c"
        ),
        "cc": "/usr/bin/riscv64-linux-gnu-g++",
        "dir": "rv"
    },
    "rvv": {
        "target": tvm.target.Target(
            "llvm -mtriple=riscv64-linux-gnu -mcpu=generic-rv64 -mabi=lp64d -mattr=+64bit,+m,+a,+f,+d,+c,+v"
        ),
        "cc": "/usr/bin/riscv64-linux-gnu-g++",
        "dir": "rvv"
    }
}

# æ‰©å±•çš„å¤§å°é…ç½®
SIZE_CONFIGS = {
    'small': {'shape_range': [(16, 16), (32, 32)]},
    'medium': {'shape_range': [(32, 32), (64, 64)]},
    'large': {'shape_range': [(64, 64), (128, 128)]},
    'xlarge': {'shape_range': [(128, 128), (256, 256)]},
    'xxlarge': {'shape_range': [(256, 256), (512, 512)]}
}


def export_op_with_platforms(op_name: str, size: str, run_id: int, base_output_dir: str = "./exported_models") -> Dict:
    """
    å¯¼å‡ºå•ä¸ªç®—å­åˆ°TFLiteå’Œä¸¤ä¸ªTVMå¹³å°(rvå’Œrvv)
    """
    # åˆ›å»ºè¿è¡Œç›®å½•
    run_dir = os.path.join(base_output_dir, f"run_{run_id}")
    tflite_dir = os.path.join(run_dir, "tflite", size)
    tvm_rv_dir = os.path.join(run_dir, "tvm", "rv", size)
    tvm_rvv_dir = os.path.join(run_dir, "tvm", "rvv", size)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(tflite_dir, exist_ok=True)
    os.makedirs(tvm_rv_dir, exist_ok=True)
    os.makedirs(tvm_rvv_dir, exist_ok=True)

    result = {
        'op_name': op_name,
        'size': size,
        'run_id': run_id,
        'tflite_path': None,
        'tvm_paths': {},
        'status': 'failed'
    }

    try:
        # 1. æ„å»ºKerasæ¨¡å‹
        print(f"ğŸ”§ è¿è¡Œ{run_id}: æ„å»º {op_name} ({size}) æ¨¡å‹...")
        model = build_op(op_name, size)

        # 2. å¯¼å‡ºä¸ºTFLite
        print(f"  å¯¼å‡ºä¸ºTFLiteæ ¼å¼...")
        tflite_model = convert_to_tflite(model, op_name)

        if tflite_model is not None:
            tflite_path = os.path.join(tflite_dir, f"{op_name}_{size}.tflite")
            with open(tflite_path, 'wb') as f:
                f.write(tflite_model)
            result['tflite_path'] = tflite_path
            print(f"    âœ“ TFLiteæ¨¡å‹å·²ä¿å­˜: {tflite_path}")
        else:
            print("    âš ï¸ TFLiteè½¬æ¢è¿”å›None")
            result['error'] = "TFLiteè½¬æ¢è¿”å›None"
            return result

        # 3. å¯¼å‡ºä¸ºTVMï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if TVM_AVAILABLE:
            result['tvm_paths'] = {}

            # ä¸ºæ¯ä¸ªå¹³å°å¯¼å‡ºTVMæ¨¡å‹
            for platform_name, platform_config in TARGET_PLATFORMS.items():
                print(f"  å¯¼å‡ºä¸ºTVM {platform_name}æ ¼å¼...")

                # é€‰æ‹©å¯¹åº”çš„è¾“å‡ºç›®å½•
                if platform_name == "rv":
                    platform_dir = tvm_rv_dir
                else:  # rvv
                    platform_dir = tvm_rvv_dir

                tvm_paths = convert_tflite_to_tvm_simple(
                    tflite_model, op_name, size, platform_dir, platform_config
                )

                if tvm_paths:
                    result['tvm_paths'][platform_name] = tvm_paths
                    print(f"    âœ“ TVM {platform_name}æ¨¡å‹å¯¼å‡ºæˆåŠŸ")
                else:
                    print(f"    âš ï¸ TVM {platform_name}æ¨¡å‹å¯¼å‡ºå¤±è´¥")
        else:
            print("    âš ï¸ TVMä¸å¯ç”¨ï¼Œè·³è¿‡TVMå¯¼å‡º")

        result['status'] = 'success'

    except Exception as e:
        print(f"âŒ å¯¼å‡º {op_name} å¤±è´¥: {e}")
        result['error'] = str(e)
        import traceback
        traceback.print_exc()

    return result


def convert_tflite_to_tvm_simple(tflite_model: bytes, op_name: str, size: str,
                                 output_dir: str, platform_config: Dict) -> Dict:
    """
    ç›´æ¥å°†TFLiteæ¨¡å‹è½¬æ¢ä¸ºTVMæ ¼å¼
    """
    if not TVM_AVAILABLE:
        return {}

    try:
        # å°†TFLiteæ¨¡å‹è½¬æ¢ä¸ºå­—èŠ‚æ•°ç»„
        tflite_model_buf = bytearray(tflite_model)

        # ä½¿ç”¨TFLiteå‰ç«¯å¯¼å…¥æ¨¡å‹
        tflite_model_obj = tflite.Model.GetRootAsModel(tflite_model_buf, 0)
        mod, params = relay.frontend.from_tflite(tflite_model_obj)

        # ç¼–è¯‘æ¨¡å‹
        with tvm.transform.PassContext(opt_level=3):
            lib = relay.build(mod, target=platform_config["target"], params=params)

        # ä¿å­˜æ–‡ä»¶
        base_name = f"{op_name}_{size}"
        base_path = os.path.join(output_dir, base_name)

        # ä¿å­˜.soæ–‡ä»¶
        so_path = f"{base_path}.so"
        lib.export_library(so_path, cc=platform_config["cc"])

        # ä¿å­˜å›¾JSON
        graph_json_path = f"{base_path}.json"
        with open(graph_json_path, 'w') as f:
            f.write(lib.get_graph_json())

        # ä¿å­˜å‚æ•°
        params_path = f"{base_path}.params"
        with open(params_path, 'wb') as f:
            f.write(tvm.runtime.save_param_dict(lib.get_params()))

        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            'op_name': op_name,
            'size': size,
            'platform': platform_config["dir"],
            'conversion_method': 'tflite_to_tvm',
            'export_time': str(np.datetime64('now'))
        }

        metadata_path = f"{base_path}_metadata.json"
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)

        return {
            'so_path': so_path,
            'graph_json_path': graph_json_path,
            'params_path': params_path,
            'metadata_path': metadata_path
        }

    except Exception as e:
        print(f"    âŒ TFLiteåˆ°TVMè½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {}


def run_tvm(tvm_path: str, output_dir: str) -> Dict:
    """
    æ‰§è¡ŒTVMæ¨¡å‹éªŒè¯
    """
    try:
        # æ„å»ºè¾“å‡ºè·¯å¾„
        output_path = os.path.join(output_dir, "tvm_output")

        # æ‰§è¡ŒéªŒè¯å‘½ä»¤
        cmd = f"/home/yan/workdir/cpp/validator-riscv /home/yan/workdir/new_test/{tvm_path} /home/yan/workdir/new_test/{output_path} --no-save-outputs"
        result = execute_command(cmd)

        print(f"æ‰§è¡Œç»“æœ: {result}")
        return {'success': True, 'result': result}

    except Exception as e:
        print(f"âŒ æ‰§è¡ŒTVMéªŒè¯å¤±è´¥: {e}")
        return {'success': False, 'error': str(e)}


def run_op_for_all_platforms(op_name: str, size: str, run_id: int, base_output_dir: str = "./exported_models") -> Dict:
    """
    ä¸ºå•ä¸ªç®—å­è¿è¡Œæ‰€æœ‰å¹³å°çš„éªŒè¯
    """
    # å¯¼å‡ºæ¨¡å‹
    export_result = export_op_with_platforms(op_name, size, run_id, base_output_dir)

    if export_result['status'] != 'success':
        return export_result

    # è¿è¡ŒéªŒè¯
    validation_results = {}

    # ä¸ºæ¯ä¸ªå¹³å°è¿è¡ŒéªŒè¯
    for platform_name, tvm_paths in export_result.get('tvm_paths', {}).items():
        if tvm_paths and 'so_path' in tvm_paths:
            print(f"ğŸ§ª è¿è¡Œ {platform_name} å¹³å°éªŒè¯...")

            # åˆ›å»ºå¹³å°ç‰¹å®šçš„è¾“å‡ºç›®å½•
            platform_output_dir = os.path.join(
                base_output_dir,
                f"run_{run_id}",
                "output",
                platform_name,
                size
            )
            os.makedirs(platform_output_dir, exist_ok=True)

            # è¿è¡ŒéªŒè¯
            validation_result = run_tvm(tvm_paths['so_path'], platform_output_dir)
            validation_results[platform_name] = validation_result

            if validation_result.get('success'):
                print(f"   âœ… {platform_name} éªŒè¯æˆåŠŸ")
            else:
                print(f"   âŒ {platform_name} éªŒè¯å¤±è´¥: {validation_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

    export_result['validation_results'] = validation_results
    return export_result


def run_all_ops_multiple_times(num_runs: int = 10,
                               sizes: List[str] = ["small", "medium", "large"],
                               base_output_dir: str = "./exported_models",
                               ops_to_run: List[str] = None) -> Dict:
    """
    å¤šæ¬¡è¿è¡Œæ‰€æœ‰ç®—å­çš„å¯¼å‡ºå’ŒéªŒè¯
    """
    # è·å–æ”¯æŒçš„ç®—å­
    generator = TFLiteOperatorGenerator()

    if ops_to_run is None:
        ops_to_run = generator.supported_ops

    all_results = []

    for run_id in range(1, num_runs + 1):
        print(f"\nğŸ”„ å¼€å§‹ç¬¬ {run_id}/{num_runs} æ¬¡è¿è¡Œ")
        run_results = []

        for op_name in ops_to_run:
            for size in sizes:
                print(f"\nğŸ¯ å¤„ç†ç®—å­: {op_name} (å¤§å°: {size})")

                # è¿è¡Œå•ä¸ªç®—å­çš„å¯¼å‡ºå’ŒéªŒè¯
                result = run_op_for_all_platforms(op_name, size, run_id, base_output_dir)
                result['size'] = size
                run_results.append(result)

                # æ˜¾ç¤ºç®€è¦ç»“æœ
                if result['status'] == 'success':
                    print(f"   âœ… {op_name} ({size}) å¯¼å‡ºæˆåŠŸ")
                    # æ˜¾ç¤ºéªŒè¯ç»“æœ
                    for platform, val_result in result.get('validation_results', {}).items():
                        status = "æˆåŠŸ" if val_result.get('success') else "å¤±è´¥"
                        print(f"      {platform}: {status}")
                else:
                    print(f"   âŒ {op_name} ({size}) å¯¼å‡ºå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        # ä¿å­˜æœ¬æ¬¡è¿è¡Œçš„ç»“æœ
        run_summary = {
            'run_id': run_id,
            'total_ops': len(ops_to_run) * len(sizes),
            'success_count': sum(1 for r in run_results if r['status'] == 'success'),
            'failed_count': sum(1 for r in run_results if r['status'] != 'success'),
            'results': run_results
        }

        # ä¿å­˜è¿è¡Œæ‘˜è¦
        run_summary_path = os.path.join(base_output_dir, f"run_{run_id}", "run_summary.json")
        with open(run_summary_path, 'w') as f:
            json.dump(run_summary, f, indent=2)

        all_results.append(run_summary)

        print(f"\nğŸ“Š ç¬¬ {run_id} æ¬¡è¿è¡Œå®Œæˆ:")
        print(f"   æˆåŠŸ: {run_summary['success_count']}/{run_summary['total_ops']}")
        print(f"   å¤±è´¥: {run_summary['failed_count']}/{run_summary['total_ops']}")

    # ç”Ÿæˆæ€»æ‘˜è¦
    total_summary = {
        'total_runs': num_runs,
        'total_ops_per_run': len(ops_to_run) * len(sizes),
        'sizes': sizes,
        'runs': all_results
    }

    # ä¿å­˜æ€»æ‘˜è¦
    total_summary_path = os.path.join(base_output_dir, "total_summary.json")
    with open(total_summary_path, 'w') as f:
        json.dump(total_summary, f, indent=2)

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_success = sum(run['success_count'] for run in all_results)
    total_failures = sum(run['failed_count'] for run in all_results)
    total_operations = num_runs * len(ops_to_run) * len(sizes)

    print(f"\nğŸ‰ æ‰€æœ‰è¿è¡Œå®Œæˆ!")
    print(f"   æ€»è¿è¡Œæ¬¡æ•°: {num_runs}")
    print(f"   æ¯æ¬¡è¿è¡Œçš„ç®—å­æ•°: {len(ops_to_run)}")
    print(f"   æµ‹è¯•çš„å¤§å°: {', '.join(sizes)}")
    print(f"   æ€»æ“ä½œæ•°: {total_operations}")
    print(f"   æ€»æˆåŠŸ: {total_success}")
    print(f"   æ€»å¤±è´¥: {total_failures}")
    if total_operations > 0:
        print(f"   æˆåŠŸç‡: {total_success / total_operations * 100:.2f}%")

    return total_summary


def main():
    """å‘½ä»¤è¡Œä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¤šæ¬¡è¿è¡Œç®—å­å¯¼å‡ºå’ŒéªŒè¯")

    parser.add_argument("--runs", type=int, default=100,
                        help="è¿è¡Œæ¬¡æ•°")
    parser.add_argument("--sizes", type=str, nargs="+",
                        choices=['small', 'medium', 'large', 'xlarge', 'xxlarge'],
                        default=['small', 'medium', 'large'],
                        help="æ¨¡å‹å¤§å°åˆ—è¡¨")
    parser.add_argument("--output-dir", type=str, default="./exported_models2",
                        help="è¾“å‡ºç›®å½•")
    parser.add_argument("--ops", type=str, nargs="+",
                        help="æŒ‡å®šè¦è¿è¡Œçš„ç®—å­åˆ—è¡¨")
    parser.add_argument("--list-ops", action="store_true",
                        help="åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„ç®—å­")
    parser.add_argument("--single-op", type=str,
                        help="è¿è¡Œå•ä¸ªç®—å­")
    parser.add_argument("--single-run", type=int,
                        help="è¿è¡Œå•æ¬¡æµ‹è¯•")

    args = parser.parse_args()

    # åˆ—å‡ºæ”¯æŒçš„ç®—å­
    if args.list_ops:
        generator = TFLiteOperatorGenerator()
        print("ğŸ“‹ æ”¯æŒçš„ç®—å­åˆ—è¡¨:")
        for i, op in enumerate(generator.supported_ops, 1):
            print(f"  {i:2d}. {op}")
        return

    # ç¡®å®šè¦è¿è¡Œçš„ç®—å­
    generator = TFLiteOperatorGenerator()
    if args.ops:
        ops_to_run = [op for op in args.ops if op in generator.supported_ops]
        if len(ops_to_run) != len(args.ops):
            print(f"âš ï¸ è­¦å‘Š: éƒ¨åˆ†ç®—å­ä¸è¢«æ”¯æŒï¼Œå·²è¿‡æ»¤")
    elif args.single_op:
        if args.single_op in generator.supported_ops:
            ops_to_run = [args.single_op]
        else:
            print(f"âŒ ç®—å­ {args.single_op} ä¸è¢«æ”¯æŒ")
            return
    else:
        ops_to_run = generator.supported_ops

    print(f"ğŸ¯ å°†è¿è¡Œä»¥ä¸‹ç®—å­: {', '.join(ops_to_run)}")
    print(f"ğŸ“ æµ‹è¯•å¤§å°: {', '.join(args.sizes)}")

    # è¿è¡Œæµ‹è¯•
    if args.single_run:
        # å•æ¬¡è¿è¡Œ
        print(f"\nğŸ”„ å¼€å§‹å•æ¬¡è¿è¡Œ (ID: {args.single_run})")
        result = run_all_ops_multiple_times(
            num_runs=1,
            sizes=args.sizes,
            base_output_dir=args.output_dir,
            ops_to_run=ops_to_run
        )
    else:
        # å¤šæ¬¡è¿è¡Œ
        result = run_all_ops_multiple_times(
            num_runs=args.runs,
            sizes=args.sizes,
            base_output_dir=args.output_dir,
            ops_to_run=ops_to_run
        )


if __name__ == "__main__":
    main()